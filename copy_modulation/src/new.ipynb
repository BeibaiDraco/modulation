{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5babe6b-3ec0-4b1e-8d2b-737eed9e9f87",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'L23_neuron_20210228_Y54_Z320_test.mat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/research/lib/python3.12/site-packages/scipy/io/matlab/_mio.py:39\u001b[0m, in \u001b[0;36m_open_file\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_like\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;66;03m# Probably \"not found\"\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'L23_neuron_20210228_Y54_Z320_test.mat'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 13\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m###############################################################################\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# 1) LOAD DATA\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m###############################################################################\u001b[39;00m\n\u001b[1;32m     12\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL23_neuron_20210228_Y54_Z320_test.mat\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Update with the correct path\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m mat_data \u001b[38;5;241m=\u001b[39m \u001b[43mscipy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloadmat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Convert MATLAB arrays to NumPy arrays\u001b[39;00m\n\u001b[1;32m     16\u001b[0m eigenface_evoked \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(mat_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEigenface_0_trials_evoked\u001b[39m\u001b[38;5;124m\"\u001b[39m])  \u001b[38;5;66;03m# (500, 1000, 4)\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/research/lib/python3.12/site-packages/scipy/io/matlab/_mio.py:225\u001b[0m, in \u001b[0;36mloadmat\u001b[0;34m(file_name, mdict, appendmat, **kwargs)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;124;03mLoad MATLAB file.\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;124;03m    3.14159265+3.14159265j])\u001b[39;00m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    224\u001b[0m variable_names \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvariable_names\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 225\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_open_file_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mappendmat\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m    \u001b[49m\u001b[43mMR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmat_reader_factory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmatfile_dict\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mMR\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_variables\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvariable_names\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/research/lib/python3.12/contextlib.py:137\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/research/lib/python3.12/site-packages/scipy/io/matlab/_mio.py:17\u001b[0m, in \u001b[0;36m_open_file_context\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;129m@contextmanager\u001b[39m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_context\u001b[39m(file_like, appendmat, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m---> 17\u001b[0m     f, opened \u001b[38;5;241m=\u001b[39m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_like\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mappendmat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     19\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m f\n",
      "File \u001b[0;32m~/miniconda3/envs/research/lib/python3.12/site-packages/scipy/io/matlab/_mio.py:45\u001b[0m, in \u001b[0;36m_open_file\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m appendmat \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m file_like\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.mat\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     44\u001b[0m         file_like \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.mat\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_like\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[1;32m     48\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReader needs file name or open file-like object\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     49\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'L23_neuron_20210228_Y54_Z320_test.mat'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io\n",
    "\n",
    "###############################################################################\n",
    "# 1) LOAD DATA\n",
    "###############################################################################\n",
    "file_path = \"L23_neuron_20210228_Y54_Z320_test.mat\"  # Update with the correct path\n",
    "mat_data = scipy.io.loadmat(file_path)\n",
    "\n",
    "# Convert MATLAB arrays to NumPy arrays\n",
    "eigenface_evoked = np.array(mat_data[\"Eigenface_0_trials_evoked\"])  # (500, 1000, 4)\n",
    "eigenface_isi    = np.array(mat_data[\"Eigenface_0_trials_isi\"])     # (500, 1000)\n",
    "dff_evoked       = np.array(mat_data[\"dFF0_trials_evoked\"])         # (229, 1000, 4)\n",
    "dff_isi          = np.array(mat_data[\"dFF0_trials_isi\"])            # (229, 1000)\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# 2) DATASET WITH PER-NEURON NORMALIZATION\n",
    "###############################################################################\n",
    "class NeuralDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Each column => x(504) = [face(500), stim(4)], y(229).\n",
    "    Per-neuron norm => y is normalized so each neuron is ~N(0,1).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, eigenface_evoked, dff_evoked,\n",
    "                 eigenface_isi, dff_isi,\n",
    "                 apply_norm=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.samples_x = []\n",
    "        self.samples_y = []\n",
    "\n",
    "        face_dim = 500\n",
    "        n_stim = 4\n",
    "\n",
    "        # Evoked\n",
    "        for c in range(n_stim):\n",
    "            face_block   = eigenface_evoked[:, :, c]  # (500, 1000)\n",
    "            neural_block = dff_evoked[:, :, c]        # (229, 1000)\n",
    "            stim_onehot = np.zeros((n_stim,), dtype=np.float32)\n",
    "            stim_onehot[c] = 1.0\n",
    "            for col in range(face_block.shape[1]):\n",
    "                face_col = face_block[:, col].astype(np.float32)\n",
    "                neural_col = neural_block[:, col].astype(np.float32)\n",
    "                x_in = np.concatenate([face_col, stim_onehot], axis=0)  # (504,)\n",
    "                self.samples_x.append(x_in)\n",
    "                self.samples_y.append(neural_col)\n",
    "\n",
    "        # ISI => zero stim\n",
    "        face_isi_block   = eigenface_isi\n",
    "        neural_isi_block = dff_isi\n",
    "        zero_stim = np.zeros((n_stim,), dtype=np.float32)\n",
    "        for col in range(face_isi_block.shape[1]):\n",
    "            face_col = face_isi_block[:, col].astype(np.float32)\n",
    "            neural_col = neural_isi_block[:, col].astype(np.float32)\n",
    "            x_in = np.concatenate([face_col, zero_stim], axis=0)\n",
    "            self.samples_x.append(x_in)\n",
    "            self.samples_y.append(neural_col)\n",
    "\n",
    "        self.samples_x = torch.tensor(np.array(self.samples_x))  # (N,504)\n",
    "        self.samples_y = torch.tensor(np.array(self.samples_y))  # (N,229)\n",
    "\n",
    "        if apply_norm:\n",
    "            self.means = self.samples_y.mean(dim=0)   # (229,)\n",
    "            self.stds  = self.samples_y.std(dim=0)    # (229,)\n",
    "            self.stds  = torch.where(self.stds<1e-9, torch.ones_like(self.stds), self.stds)\n",
    "            self.samples_y= (self.samples_y - self.means)/ self.stds\n",
    "        else:\n",
    "            self.means = torch.zeros((229,), dtype=torch.float32)\n",
    "            self.stds  = torch.ones((229,), dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples_x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.samples_x[idx], self.samples_y[idx]\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# 3) MULTI-BRANCH MLP\n",
    "###############################################################################\n",
    "class MultiBranchMLP(nn.Module):\n",
    "    def __init__(self,\n",
    "                 face_dim=500, stim_dim=4,\n",
    "                 hidden_face=[1024,512,256],\n",
    "                 hidden_stim=[128,64],\n",
    "                 hidden_fuse=[256,128],\n",
    "                 output_dim=229):\n",
    "        super().__init__()\n",
    "\n",
    "        # face branch\n",
    "        face_layers = []\n",
    "        in_dim = face_dim\n",
    "        for hdim in hidden_face:\n",
    "            face_layers.append(nn.Linear(in_dim, hdim))\n",
    "            face_layers.append(nn.ReLU())\n",
    "            in_dim = hdim\n",
    "        self.face_net = nn.Sequential(*face_layers)\n",
    "\n",
    "        # stim branch\n",
    "        stim_layers = []\n",
    "        in_dim_s= stim_dim\n",
    "        for hdim_s in hidden_stim:\n",
    "            stim_layers.append(nn.Linear(in_dim_s, hdim_s))\n",
    "            stim_layers.append(nn.ReLU())\n",
    "            in_dim_s= hdim_s\n",
    "        self.stim_net= nn.Sequential(*stim_layers)\n",
    "\n",
    "        # fuse\n",
    "        fuse_in= hidden_face[-1] + hidden_stim[-1]\n",
    "        fuse_seq= []\n",
    "        prev_dim= fuse_in\n",
    "        for fdim in hidden_fuse:\n",
    "            fuse_seq.append(nn.Linear(prev_dim, fdim))\n",
    "            fuse_seq.append(nn.ReLU())\n",
    "            prev_dim= fdim\n",
    "        fuse_seq.append(nn.Linear(prev_dim, output_dim))\n",
    "        self.fuse= nn.Sequential(*fuse_seq)\n",
    "\n",
    "    def forward(self, x):\n",
    "        face_part= x[:, :500]\n",
    "        stim_part= x[:, 500:]\n",
    "        face_out= self.face_net(face_part)\n",
    "        stim_out= self.stim_net(stim_part)\n",
    "        combined= torch.cat([face_out, stim_out], dim=-1)\n",
    "        out= self.fuse(combined)  # (B,229)\n",
    "        return out\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# 4) COMBINED LOSS\n",
    "###############################################################################\n",
    "def correlation_loss(y_pred, y_true, eps=1e-8):\n",
    "    y_pred_f= y_pred.view(-1)\n",
    "    y_true_f= y_true.view(-1)\n",
    "    pm= y_pred_f.mean()\n",
    "    tm= y_true_f.mean()\n",
    "    cov= ((y_pred_f-pm)*(y_true_f-tm)).sum()\n",
    "    var1= ((y_pred_f-pm)**2).sum()+eps\n",
    "    var2= ((y_true_f-tm)**2).sum()+eps\n",
    "    corr= cov/(var1.sqrt()*var2.sqrt())\n",
    "    return 1.0- corr\n",
    "\n",
    "def combined_loss(y_pred, y_true, alpha=0.5):\n",
    "    mse_v= ((y_pred- y_true)**2).mean()\n",
    "    corr_v= correlation_loss(y_pred, y_true)\n",
    "    return alpha*mse_v+ (1-alpha)*corr_v\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# 5) R^2 HELPER\n",
    "###############################################################################\n",
    "def compute_r2(model, loader, ds, device='cuda'):\n",
    "    \"\"\"\n",
    "    We'll pass the entire loader to the model, invert normalization, \n",
    "    and compute average R^2 across all neurons.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_preds= []\n",
    "    all_true= []\n",
    "    with torch.no_grad():\n",
    "        for x_batch,y_batch_norm in loader:\n",
    "            x_batch= x_batch.to(device)\n",
    "            y_batch_norm= y_batch_norm.to(device)\n",
    "            preds_norm= model(x_batch)  # shape(B,229)\n",
    "            # invert\n",
    "            means= ds.means.to(device)   # shape(229,)\n",
    "            stds= ds.stds.to(device)\n",
    "            preds_raw= preds_norm*stds + means\n",
    "            true_raw= y_batch_norm*stds + means\n",
    "            all_preds.append(preds_raw.cpu().numpy())\n",
    "            all_true.append(true_raw.cpu().numpy())\n",
    "    all_preds= np.concatenate(all_preds, axis=0) # (N,229)\n",
    "    all_true= np.concatenate(all_true, axis=0)\n",
    "    # measure average R^2\n",
    "    n_neurons= all_preds.shape[1]\n",
    "    r2_arr= []\n",
    "    for n in range(n_neurons):\n",
    "        y_t= all_true[:,n]\n",
    "        y_p= all_preds[:,n]\n",
    "        ss_res= np.sum((y_t-y_p)**2)\n",
    "        ss_tot= np.sum((y_t- np.mean(y_t))**2)\n",
    "        if ss_tot>1e-12:\n",
    "            r2_arr.append(1- ss_res/ ss_tot)\n",
    "        else:\n",
    "            r2_arr.append(0.0)\n",
    "    return np.mean(r2_arr)\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# 6) TRAIN FUNCTION\n",
    "###############################################################################\n",
    "def train_model(eigenface_evoked, dff_evoked,\n",
    "                eigenface_isi, dff_isi,\n",
    "                epochs=100, batch_size=64, lr=1e-3,\n",
    "                alpha=0.5,\n",
    "                device='cuda'):\n",
    "    \n",
    "    ds_full= NeuralDataset(eigenface_evoked, dff_evoked, eigenface_isi, dff_isi,\n",
    "                           apply_norm=True)\n",
    "    N= len(ds_full)\n",
    "    val_size= int(0.2*N)\n",
    "    train_size= N- val_size\n",
    "    train_ds, val_ds= random_split(ds_full,[train_size, val_size])\n",
    "    train_loader= DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "    val_loader= DataLoader(val_ds, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    model= MultiBranchMLP(\n",
    "        face_dim=500, stim_dim=4,\n",
    "        hidden_face=[1024,512,256],\n",
    "        hidden_stim=[128,64],\n",
    "        hidden_fuse=[256,128],\n",
    "        output_dim=229\n",
    "    ).to(device)\n",
    "\n",
    "    optimizer= optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler= optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min',\n",
    "                                                    factor=0.5, patience=5, verbose=True)\n",
    "\n",
    "    best_val_loss= float('inf')\n",
    "    best_state= None\n",
    "    patience=0\n",
    "    max_patience=50\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # 1) Train\n",
    "        model.train()\n",
    "        total_loss= 0.0\n",
    "        for x_batch,y_batch in train_loader:\n",
    "            x_batch= x_batch.to(device)\n",
    "            y_batch= y_batch.to(device)\n",
    "            pred= model(x_batch)\n",
    "            loss= combined_loss(pred,y_batch, alpha=alpha)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss+= loss.item()\n",
    "        train_loss= total_loss/ len(train_loader)\n",
    "\n",
    "        # 2) Validation\n",
    "        model.eval()\n",
    "        val_loss_sum= 0.0\n",
    "        with torch.no_grad():\n",
    "            for x_val, y_val in val_loader:\n",
    "                x_val= x_val.to(device)\n",
    "                y_val= y_val.to(device)\n",
    "                preds_val= model(x_val)\n",
    "                lv= combined_loss(preds_val,y_val, alpha=alpha)\n",
    "                val_loss_sum+= lv.item()\n",
    "        val_loss= val_loss_sum/ len(val_loader)\n",
    "\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        # 3) Only every 20 epochs => compute train R^2, val R^2\n",
    "        #   or last epoch => or epoch==epochs-1\n",
    "        do_print= (epoch%20==0 or epoch== epochs-1)\n",
    "        if do_print:\n",
    "            train_r2= compute_r2(model, train_loader, ds_full, device=device)\n",
    "            val_r2  = compute_r2(model, val_loader, ds_full, device=device)\n",
    "            print(f\"Epoch {epoch+1}/{epochs}, train_loss={train_loss:.4f}, val_loss={val_loss:.4f}, \"\n",
    "                  f\"train_R^2={train_r2:.4f}, val_R^2={val_r2:.4f}\")\n",
    "            \n",
    "\n",
    "        # 4) Early stopping\n",
    "        if val_loss< best_val_loss -1e-9:\n",
    "            best_val_loss= val_loss\n",
    "            best_state= model.state_dict()\n",
    "            patience=0\n",
    "        else:\n",
    "            patience+=1\n",
    "            if patience>= max_patience:\n",
    "                print(\"Early stopping triggered.\")\n",
    "                break\n",
    "\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "    print(f\"Training done. Best val loss= {best_val_loss:.5f}\")\n",
    "\n",
    "    # Return the model + the dataset\n",
    "    return model, ds_full\n",
    "\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# 8) MAIN\n",
    "###############################################################################\n",
    "if __name__==\"__main__\":\n",
    "    device= 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "    model, ds_full= train_model(\n",
    "        eigenface_evoked, dff_evoked,\n",
    "        eigenface_isi, dff_isi,\n",
    "        epochs=150,\n",
    "        batch_size=64,\n",
    "        lr=1e-3,\n",
    "        alpha=0.5,\n",
    "        device=device\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36097209-31f6-4035-bd3d-7beff0b006fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def invert_normalization(pred_norm, ds):\n",
    "    \"\"\"\n",
    "    Convert predicted normalized (N,229) back to raw domain using ds.means, ds.stds.\n",
    "    \"\"\"\n",
    "    device = pred_norm.device\n",
    "    means = ds.means.to(device)   # shape(229,)\n",
    "    stds  = ds.stds.to(device)\n",
    "    return pred_norm*stds + means\n",
    "\n",
    "def analyze_face_stim_orthogonality(model, ds_full, \n",
    "                                    M=100, K=10,\n",
    "                                    sub_pcs=3,\n",
    "                                    device='cuda',\n",
    "                                    random_seed=None,\n",
    "                                    null_hypothesis_mode=False):\n",
    "    \"\"\"\n",
    "    1) Baseline => x_base=0 => model => y_base\n",
    "    2) Face-driven => keep face from real sample, set stim=0\n",
    "    3) Stim-driven => keep stim from real sample, set face=0\n",
    "    4) Possibly do a 'null hypothesis' mode: e.g. face vs. face or random scramble\n",
    "    5) measure subspace overlap\n",
    "    6) 2D PCA plot\n",
    "    \"\"\"\n",
    "\n",
    "    model.eval()\n",
    "    if random_seed is not None:\n",
    "        np.random.seed(random_seed)\n",
    "        torch.manual_seed(random_seed)\n",
    "\n",
    "    # Baseline\n",
    "    x_base = torch.zeros(1,504, dtype=torch.float32).to(device)\n",
    "    with torch.no_grad():\n",
    "        y_base_norm= model(x_base)[0]  # shape(229,)\n",
    "\n",
    "    N= len(ds_full)\n",
    "    \n",
    "    if not null_hypothesis_mode:\n",
    "        # normal scenario => face vs. stim\n",
    "        idxs= np.random.choice(N, M+K, replace=False)\n",
    "        face_idxs= idxs[:M]\n",
    "        stim_idxs= idxs[M:]\n",
    "\n",
    "        # face-driven\n",
    "        x_face_list= []\n",
    "        for i in face_idxs:\n",
    "            x_raw,_= ds_full[i]\n",
    "            x_mod= x_raw.clone()\n",
    "            # zero out stim => last 4\n",
    "            x_mod[500:]= 0.0\n",
    "            x_face_list.append(x_mod)\n",
    "        x_face_all= torch.stack(x_face_list, dim=0).to(device)\n",
    "        with torch.no_grad():\n",
    "            y_face_norm= model(x_face_all)\n",
    "        y_face_norm= y_face_norm - y_base_norm\n",
    "\n",
    "        # stim-driven\n",
    "        x_stim_list= []\n",
    "        for j in stim_idxs:\n",
    "            x_raw,_= ds_full[j]\n",
    "            x_mod= x_raw.clone()\n",
    "            # zero out face => first 500\n",
    "            x_mod[:500]=0.0\n",
    "            x_stim_list.append(x_mod)\n",
    "        x_stim_all= torch.stack(x_stim_list, dim=0).to(device)\n",
    "        with torch.no_grad():\n",
    "            y_stim_norm= model(x_stim_all)\n",
    "        y_stim_norm= y_stim_norm- y_base_norm\n",
    "\n",
    "        # invert to raw\n",
    "        y_face_raw= invert_normalization(y_face_norm, ds_full)\n",
    "        y_stim_raw= invert_normalization(y_stim_norm, ds_full)\n",
    "\n",
    "        face_np= y_face_raw.cpu().numpy()\n",
    "        stim_np= y_stim_raw.cpu().numpy()\n",
    "\n",
    "        label_face= 'Face-driven'\n",
    "        label_stim= 'Stim-driven'\n",
    "\n",
    "    else:\n",
    "        # Null hypothesis => let's do face vs face, i.e. two random subsets of face columns\n",
    "        # so we can see how \"angle\" might appear if there's actually no difference\n",
    "        # We'll do M, K from the dataset but both sets are \"face=some real face, stim=0\"\n",
    "        idxs= np.random.choice(N, M+K, replace=False)\n",
    "        setA_idxs= idxs[:M]\n",
    "        setB_idxs= idxs[M:]\n",
    "\n",
    "        xA_list= []\n",
    "        for i in setA_idxs:\n",
    "            x_raw,_= ds_full[i]\n",
    "            x_mod= x_raw.clone()\n",
    "            x_mod[500:]= 0.0\n",
    "            xA_list.append(x_mod)\n",
    "        xA_all= torch.stack(xA_list, dim=0).to(device)\n",
    "        with torch.no_grad():\n",
    "            yA_norm= model(xA_all)\n",
    "        yA_norm= yA_norm- y_base_norm\n",
    "        yA_raw= invert_normalization(yA_norm, ds_full)\n",
    "        setA_np= yA_raw.cpu().numpy()\n",
    "\n",
    "        xB_list= []\n",
    "        for j in setB_idxs:\n",
    "            x_raw,_= ds_full[j]\n",
    "            x_mod= x_raw.clone()\n",
    "            x_mod[500:]= 0.0\n",
    "            xB_list.append(x_mod)\n",
    "        xB_all= torch.stack(xB_list, dim=0).to(device)\n",
    "        with torch.no_grad():\n",
    "            yB_norm= model(xB_all)\n",
    "        yB_norm= yB_norm- y_base_norm\n",
    "        yB_raw= invert_normalization(yB_norm, ds_full)\n",
    "        setB_np= yB_raw.cpu().numpy()\n",
    "\n",
    "        face_np= setA_np\n",
    "        stim_np= setB_np\n",
    "        label_face= 'Set A (face/fake)'\n",
    "        label_stim= 'Set B (face/fake)'\n",
    "\n",
    "    # measure subspace overlap\n",
    "    from sklearn.decomposition import PCA\n",
    "    pca_face= PCA(n_components=sub_pcs).fit(face_np)\n",
    "    U_face= pca_face.components_.T\n",
    "    pca_stim= PCA(n_components=sub_pcs).fit(stim_np)\n",
    "    U_stim= pca_stim.components_.T\n",
    "\n",
    "    overlap= np.linalg.norm(U_face.T@ U_stim, 'fro')**2\n",
    "    print(f\"Subspace overlap (top {sub_pcs} PCs) = {overlap:.4f}\")\n",
    "\n",
    "    # angle top1\n",
    "    face_pc1= U_face[:,0]\n",
    "    stim_pc1= U_stim[:,0]\n",
    "    dot= np.dot(face_pc1, stim_pc1)\n",
    "    denom= np.linalg.norm(face_pc1)* np.linalg.norm(stim_pc1)+1e-12\n",
    "    angle_deg= np.degrees(np.arccos(dot/ denom))\n",
    "    print(f\"Angle between top1 PC: {angle_deg:.2f} deg\")\n",
    "\n",
    "    # 2D PCA\n",
    "    all_data= np.concatenate([face_np, stim_np], axis=0)\n",
    "    pca_2d= PCA(n_components=2)\n",
    "    all_2d= pca_2d.fit_transform(all_data)\n",
    "    M_= face_np.shape[0]\n",
    "    plt.figure(figsize=(6,5))\n",
    "    plt.scatter(all_2d[:M_,0], all_2d[:M_,1], c='blue', alpha=0.6, label=label_face)\n",
    "    plt.scatter(all_2d[M_:,0], all_2d[M_:,1], c='red', alpha=0.6, label=label_stim)\n",
    "    plt.title(\"Face vs. Stim subspace\" if not null_hypothesis_mode else \"Null Hypothesis (face vs. face)\")\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e972e5-71a1-4826-bed4-0b9df414903d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Real face vs. stim:\n",
    "torch.manual_seed(0)\n",
    "analyze_face_stim_orthogonality(model, ds_full, M=200, K=300,\n",
    "                                device=device,\n",
    "                                random_seed=111,\n",
    "                                null_hypothesis_mode=False)\n",
    "\n",
    "# Null hypothesis => face vs. face\n",
    "analyze_face_stim_orthogonality(model, ds_full, M=200, K=300,\n",
    "                                device=device,\n",
    "                                random_seed=111,\n",
    "                                null_hypothesis_mode=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828ccb1a-151a-4785-ab98-624d4f85e273",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "###############################################################################\n",
    "# 1) Helper: invert MLP’s per-neuron normalization to raw neural space\n",
    "###############################################################################\n",
    "def invert_normalization(y_norm, means, stds):\n",
    "    \"\"\"\n",
    "    y_norm: shape(..., 229) in normalized space\n",
    "    means, stds: shape(229,)\n",
    "    \"\"\"\n",
    "    return y_norm* stds + means\n",
    "\n",
    "###############################################################################\n",
    "# 2) Build Stimulus Subspace R\n",
    "###############################################################################\n",
    "def build_stimulus_subspace(model, dataset, device='cuda'):\n",
    "    \"\"\"\n",
    "    We'll create an (N=229, S) matrix R of trial-averaged predicted responses \n",
    "    for each of the S stimuli in the dataset. \n",
    "    For example, if we have 4 stimuli, S=4 => shape(229,4).\n",
    "\n",
    "    Steps:\n",
    "      - Identify which columns in dataset belong to each stimulus c in [0..3].\n",
    "      - Predict with the MLP -> shape(229) for each sample, invert normalization \n",
    "        to get raw neural domain.\n",
    "      - Average across those samples. => col c => R[:, c]\n",
    "    Returns R in shape(229, S).\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    n_stim = 4  # or however many stimuli\n",
    "    # We'll accumulate lists: for each c in [0..3], store predicted raw neural\n",
    "    preds_per_stim = [[] for _ in range(n_stim)]\n",
    "    \n",
    "    # We have means, std in dataset\n",
    "    means = dataset.means.cpu().numpy()   # shape(229,)\n",
    "    stds  = dataset.stds.cpu().numpy()\n",
    "\n",
    "    loader = DataLoader(dataset, batch_size=128, shuffle=False)\n",
    "    with torch.no_grad():\n",
    "        for x_batch, y_batch_norm in loader:\n",
    "            # x_batch shape(B,504)\n",
    "            # we see the last 4 dims to find the index of the 1-hot stim? \n",
    "            # Or if it's a \"zero-stim\" for ISI. \n",
    "            # We'll do argmax or something to identify c\n",
    "            x_batch = x_batch.to(device)\n",
    "            preds_norm = model(x_batch)  # shape(B,229) in normalized domain\n",
    "            # invert to raw\n",
    "            preds_raw = preds_norm* torch.tensor(stds, device=device) \\\n",
    "                        + torch.tensor(means, device=device)\n",
    "\n",
    "            x_batch_cpu = x_batch.cpu().numpy()\n",
    "            preds_raw_cpu = preds_raw.cpu().numpy()  # shape(B,229)\n",
    "\n",
    "            for i in range(x_batch_cpu.shape[0]):\n",
    "                # identify which stimulus\n",
    "                stim_vec = x_batch_cpu[i, 500:]  # shape(4,)\n",
    "                c_idx = np.argmax(stim_vec)  # either 0..3 or 0 if all zero => ISI\n",
    "                # if sum(stim_vec)==0 => no stim => we define c_idx=some code or treat it as 4th? \n",
    "                # We'll do if np.allclose(stim_vec,0): c_idx= -1 => \"ISI\"\n",
    "                # but for simplicity, we do only c_idx in [0..3], \n",
    "                # or skip if it's \"ISI\"? up to you\n",
    "                if np.allclose(stim_vec,0):\n",
    "                    # no stim => e.g. treat as c_idx= -1 or skip\n",
    "                    # We'll skip from R if you don't want to count it as a \"stim\" \n",
    "                    continue\n",
    "                else:\n",
    "                    preds_per_stim[c_idx].append(preds_raw_cpu[i])  # shape(229,)\n",
    "\n",
    "    # Now average for each c\n",
    "    # We'll build R => shape(229, S)\n",
    "    R_list = []\n",
    "    for c in range(n_stim):\n",
    "        if len(preds_per_stim[c])>0:\n",
    "            arr_c = np.stack(preds_per_stim[c], axis=0)  # shape(#samples_c,229)\n",
    "            mean_c= arr_c.mean(axis=0)                   # shape(229,)\n",
    "            R_list.append(mean_c)\n",
    "        else:\n",
    "            # no samples => put 0 vector\n",
    "            R_list.append(np.zeros((229,), dtype=np.float32))\n",
    "\n",
    "    # shape => (S,229), we transpose => (229,S)\n",
    "    R_stim = np.stack(R_list, axis=1)  # shape(229, n_stim)\n",
    "    return R_stim\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# 3) Reduced-Rank Regression => from Face(PC) to MLP's predicted neural activity\n",
    "###############################################################################\n",
    "def do_RRR_face_to_neural(model, dataset, rank=32, device='cuda'):\n",
    "    \"\"\"\n",
    "    We'll do a simplified approach:\n",
    "      - gather face data + predicted neural from the entire dataset\n",
    "      - reduce face to e.g. 32 PCs\n",
    "      - do a low-rank regression => Y = A X, with rank <= rank => we factor out => E_B x F_B^T\n",
    "    Returns E_B => shape(229, rank) as the \"behavior subspace.\"\n",
    "    \"\"\"\n",
    "    # 1) collect big X => shape(Nsamples, 500) for face, Y => shape(Nsamples, 229) in raw domain \n",
    "    #    We'll do same approach: x[:500], x[500:] => which might hold the one-hot stim. We only want face\n",
    "    #    Then predict or take the MLP predicted? Actually, for RRR we want to do it from face => real neural or MLP predicted neural? \n",
    "    #    The snippet used real neural. But let's replicate with MLP predicted neural?\n",
    "\n",
    "    # We'll gather face + neural pred in raw domain\n",
    "    # For a real approach, you'd gather face + real neural data. \n",
    "    # Here we do face + MLP predicted? Let's do face + MLP predicted for demonstration.\n",
    "\n",
    "    means = dataset.means.to(device)  # shape(229,)\n",
    "    stds  = dataset.stds.to(device)\n",
    "\n",
    "    loader = DataLoader(dataset, batch_size=128, shuffle=False)\n",
    "    face_data_list = []\n",
    "    neural_pred_list= []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x_batch, y_batch_norm in loader:\n",
    "            x_batch= x_batch.to(device)\n",
    "            # face => x_batch[:, :500]\n",
    "            face_data_list.append(x_batch[:, :500].cpu().numpy())\n",
    "            # neural pred => invert raw\n",
    "            preds_norm= model(x_batch)\n",
    "            preds_raw= preds_norm* stds + means\n",
    "            neural_pred_list.append(preds_raw.cpu().numpy())\n",
    "\n",
    "    face_all = np.concatenate(face_data_list, axis=0)   # shape(Nsamples,500)\n",
    "    neural_all= np.concatenate(neural_pred_list, axis=0)# shape(Nsamples,229)\n",
    "\n",
    "    # 2) reduce face by PCA => say keep 32 PCs if 500 is large\n",
    "    # do PCA => face (Nsamples, 500)\n",
    "    keep_f= 32\n",
    "    from sklearn.decomposition import PCA\n",
    "    pca_face= PCA(n_components=keep_f)\n",
    "    face_all_pcs = pca_face.fit_transform(face_all) # shape(Nsamples, keep_f)\n",
    "\n",
    "    # 3) do a linear regression => Y ~ A * (face_all_pcs)\n",
    "    # then we do a rank-limited approach => a SVD on the best fit matrix or partial least squares\n",
    "    # We'll do the direct approach: best-fit = Y X^+\n",
    "    # shape => Y: (Nsamples,229), X: (Nsamples, keep_f)\n",
    "    # => A => shape(229, keep_f)\n",
    "    # then we'll do an SVD and keep top=rank\n",
    "    X_ = face_all_pcs  # shape(Nsamples, keep_f)\n",
    "    Y_ = neural_all    # shape(Nsamples, 229)\n",
    "    # solve => A = Y_+.T X_ => we do pseudo-inverse or normal eq\n",
    "    # normal eq => A => (X^T X)^-1 X^T Y => shape(keep_f,229)\n",
    "    # we want A^T => shape(229, keep_f)\n",
    "    XtX= X_.T@ X_\n",
    "    XtY= X_.T@ Y_   # shape(keep_f, 229)\n",
    "    A_ = np.linalg.pinv(XtX)@ XtY   # shape(keep_f,229)\n",
    "    A_ = A_.T  # shape(229, keep_f)\n",
    "\n",
    "    # 4) do SVD => A_ => shape(229, keep_f). We keep top=rank columns => E_B => shape(229, rank)\n",
    "    Ua, Sa, VaT= np.linalg.svd(A_, full_matrices=False)  # A_= U diag S VaT\n",
    "    # shape(Ua)= (229,  keep_f), shape(Sa)= (min(229, keep_f)), shape(VaT)= (keep_f, keep_f)\n",
    "    r_ = min(rank, keep_f, 229)\n",
    "    E_B = Ua[:, :r_]  # shape(229, r_)\n",
    "    # This E_B is the \"behavior subspace\"\n",
    "    return E_B\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# 4) SVD approach to find shared dimension, then “stim-only,” “beh-only,” etc.\n",
    "###############################################################################\n",
    "def find_shared_and_measure_variance(R, E_B, test_data, sub_dims=32):\n",
    "    \"\"\"\n",
    "    R shape(229, S) => Stim subspace (S up to 32 stimuli).\n",
    "    E_B shape(229, r) => Behavior subspace from RRR\n",
    "    We'll do SVD(E_B^T R).\n",
    "    Then measure how much variance in test_data is in the shared dimension, etc.\n",
    "\n",
    "    test_data => shape(229, T). We'll measure variance in subspaces:\n",
    "      - shared_dim => top left singular vector in N-dim\n",
    "      - stim-only => R after projecting out shared\n",
    "      - beh-only => E_B after projecting out shared\n",
    "    \"\"\"\n",
    "\n",
    "    # 1) Possibly orthonormalize R, E_B\n",
    "    # if S < sub_dims, we just keep them as is, or do a small SVD. Let's do a QR on each for an orthonormal basis\n",
    "    Qr, _= np.linalg.qr(R)   # shape(229, S)\n",
    "    Qb, _= np.linalg.qr(E_B) # shape(229, r)\n",
    "    \n",
    "    # 2) M= Qb^T Qr => shape(r, S)\n",
    "    M = Qb.T@ Qr\n",
    "    U_, s_, Vt_ = np.linalg.svd(M, full_matrices=False)\n",
    "    # top singular vector => U_[:,0] in r-dim => the direction in Qb\n",
    "    # => shared_dim in N-dim => Qb @ U_[:,0]\n",
    "    u_b = U_[:,0]\n",
    "    shared_dim= Qb @ u_b  # shape(229,)\n",
    "    # normalize\n",
    "    norm_sh= np.linalg.norm(shared_dim)\n",
    "    if norm_sh>1e-12:\n",
    "        shared_dim/= norm_sh\n",
    "\n",
    "    # 3) stim-only => project out shared_dim from Qr\n",
    "    def project_out(subspace, vec):\n",
    "        proj= vec.reshape(-1,1)@(vec.reshape(1,-1)@ subspace)\n",
    "        return subspace- proj\n",
    "    Qr_wo = project_out(Qr, shared_dim)\n",
    "    # re-orthonormalize\n",
    "    Qr_wo, _= np.linalg.qr(Qr_wo)\n",
    "\n",
    "    # 4) beh-only => project out shared_dim from Qb\n",
    "    Qb_wo = project_out(Qb, shared_dim)\n",
    "    Qb_wo, _= np.linalg.qr(Qb_wo)\n",
    "\n",
    "    # measure variance\n",
    "    # test_data => shape(229, T)\n",
    "    def project_var(data, basis):\n",
    "        coords= basis.T@ data  # shape(d, T)\n",
    "        return np.sum(coords**2)/ data.shape[1]  # average\n",
    "\n",
    "    var_shared= project_var(test_data, shared_dim.reshape(-1,1))\n",
    "    var_stim_only= project_var(test_data, Qr_wo)\n",
    "    var_beh_only= project_var(test_data, Qb_wo)\n",
    "    total_var= np.sum(test_data**2)/ test_data.shape[1]\n",
    "\n",
    "    return var_shared, var_stim_only, var_beh_only, total_var, shared_dim\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# 5) Putting it All Together\n",
    "###############################################################################\n",
    "def full_subspace_analysis(model, dataset, device='cuda'):\n",
    "    \"\"\"\n",
    "    1) Build R => shape(229, S) from the MLP's predictions, averaging per stimulus.\n",
    "    2) Build E_B => from RRR of face => MLP predicted neural.\n",
    "    3) SVD => find shared dimension, measure variance in test data\n",
    "    4) Print or plot results\n",
    "    \"\"\"\n",
    "    # 1) Stim subspace\n",
    "    R_stim= build_stimulus_subspace(model, dataset, device=device)  # shape(229, S)\n",
    "    print(\"R_stim shape:\", R_stim.shape)\n",
    "\n",
    "    # 2) Behavior subspace => do RRR\n",
    "    E_B= do_RRR_face_to_neural(model, dataset, rank=32, device=device)  # shape(229, rank)\n",
    "    print(\"E_B shape:\", E_B.shape)\n",
    "\n",
    "    # 3) build test_data => shape(229, T). \n",
    "    # for demonstration, let's just gather the entire dataset in raw domain\n",
    "    # (some code is repeated from do_RRR, but we'll do it again for clarity)\n",
    "    means= dataset.means.cpu().numpy()  # shape(229,)\n",
    "    stds = dataset.stds.cpu().numpy()\n",
    "    loader= DataLoader(dataset, batch_size=128, shuffle=False)\n",
    "    all_preds=[]\n",
    "    with torch.no_grad():\n",
    "        for x_batch,y_batch_norm in loader:\n",
    "            x_batch= x_batch.to(device)\n",
    "            preds_norm= model(x_batch) # shape(B,229)\n",
    "            preds_raw= preds_norm* torch.tensor(stds, device=device) \\\n",
    "                        + torch.tensor(means, device=device)\n",
    "            all_preds.append(preds_raw.cpu().numpy())\n",
    "    test_data= np.concatenate(all_preds, axis=0).T  # shape(229, T)\n",
    "    print(\"test_data shape:\", test_data.shape)\n",
    "\n",
    "    # 4) find shared dimension => measure variance\n",
    "    var_shared, var_stim, var_beh, total_var, shared_dim= \\\n",
    "        find_shared_and_measure_variance(R_stim, E_B, test_data, sub_dims=32)\n",
    "    print(f\"Variance in shared dimension: {var_shared:.4f}\")\n",
    "    print(f\"Variance in stim-only subspace: {var_stim:.4f}\")\n",
    "    print(f\"Variance in beh-only subspace: {var_beh:.4f}\")\n",
    "    print(f\"Total variance in test data: {total_var:.4f}\")\n",
    "    # optional ratio\n",
    "    print(\"Fraction of total variance in shared:\", var_shared/ total_var)\n",
    "    print(\"Fraction of total in stim-only:\", var_stim/ total_var)\n",
    "    print(\"Fraction of total in beh-only:\", var_beh/ total_var)\n",
    "\n",
    "    # You can also do classification or further analysis in each subspace, \n",
    "    # replicate the snippet's approach for \"multiplicative gain\", etc.\n",
    "    # ...\n",
    "\n",
    "###############################################################################\n",
    "# USAGE EXAMPLE\n",
    "###############################################################################\n",
    "def main_analysis(model, dataset, device='cuda'):\n",
    "    \"\"\"\n",
    "    After you train your MLP, call this for the advanced subspace approach.\n",
    "    \"\"\"\n",
    "    full_subspace_analysis(model, dataset, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafb0a74-9265-43e9-9cdf-f087ff560592",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_analysis(model, ds_full, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05de99cf-650e-47dd-bb9c-0a18ad8d7478",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "###############################################################################\n",
    "# 0) Helper: invert MLP's normalized outputs => raw domain\n",
    "###############################################################################\n",
    "def invert_normalization(y_norm, ds):\n",
    "    \"\"\"\n",
    "    y_norm: shape(..., 229)\n",
    "    ds.means, ds.stds => shape(229,)\n",
    "    Returns raw domain neural (229D).\n",
    "    \"\"\"\n",
    "    device= y_norm.device\n",
    "    means= ds.means.to(device)\n",
    "    stds= ds.stds.to(device)\n",
    "    return y_norm* stds + means\n",
    "\n",
    "###############################################################################\n",
    "# 1) Build Face Subspace from MLP\n",
    "###############################################################################\n",
    "def build_face_subspace(model, ds, \n",
    "                        face_samples=500, \n",
    "                        subspace_dim=10, \n",
    "                        device='cuda'):\n",
    "    \"\"\"\n",
    "    We'll sample many face vectors from ds, set stim=0 => get MLP's predicted neural => raw domain => PCA => top subspace_dim PCs => face_subspace.\n",
    "\n",
    "    Steps:\n",
    "      1) sample random or systematic face inputs from ds\n",
    "      2) x_mod => shape(504,) => x_mod[500:]=0 => no stim\n",
    "      3) MLP => predicted neural in normalized domain => invert => raw domain => collect\n",
    "      4) PCA => top subspace_dim => face_subspace shape(229, subspace_dim)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    N= len(ds)\n",
    "    # pick random face_samples from ds\n",
    "    idxs= np.random.choice(N, face_samples, replace=False)\n",
    "\n",
    "    means= ds.means.to(device)\n",
    "    stds= ds.stds.to(device)\n",
    "\n",
    "    face_outputs=[]\n",
    "    for i in idxs:\n",
    "        x_raw, _= ds[i]  # shape(504,)\n",
    "        x_mod= x_raw.clone()\n",
    "        # zero out stimulus\n",
    "        x_mod[500:]= 0.0\n",
    "        x_batch= x_mod.unsqueeze(0).to(device)\n",
    "        with torch.no_grad():\n",
    "            y_pred_norm= model(x_batch)  # (1,229)\n",
    "        y_pred_raw= invert_normalization(y_pred_norm, ds)  # (1,229)\n",
    "        face_outputs.append(y_pred_raw.cpu().numpy()[0])  # shape(229,)\n",
    "\n",
    "    face_arr= np.stack(face_outputs, axis=0)  # shape(face_samples,229)\n",
    "    # do PCA => top subspace_dim\n",
    "    pca= PCA(n_components=subspace_dim)\n",
    "    pca.fit(face_arr)  # shape(#samples, 229)\n",
    "    # subspace => shape(229, subspace_dim)\n",
    "    face_subspace= pca.components_.T\n",
    "    return face_subspace\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# 2) Build Stimulus Subspace from MLP\n",
    "###############################################################################\n",
    "def build_stim_subspace(model, ds, \n",
    "                        stim_samples=500,\n",
    "                        subspace_dim=10,\n",
    "                        device='cuda'):\n",
    "    \"\"\"\n",
    "    We'll sample many stimulus vectors from ds, set face=0 => get MLP's predicted neural => raw domain => PCA => top subspace_dim => stim_subspace.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    N= len(ds)\n",
    "    idxs= np.random.choice(N, stim_samples, replace=False)\n",
    "\n",
    "    means= ds.means.to(device)\n",
    "    stds= ds.stds.to(device)\n",
    "\n",
    "    stim_outputs=[]\n",
    "    for i in idxs:\n",
    "        x_raw,_= ds[i]\n",
    "        x_mod= x_raw.clone()\n",
    "        # zero out face => x_mod[:500]=0\n",
    "        x_mod[:500]= 0.0\n",
    "        x_batch= x_mod.unsqueeze(0).to(device)\n",
    "        with torch.no_grad():\n",
    "            y_pred_norm= model(x_batch)\n",
    "        y_pred_raw= invert_normalization(y_pred_norm, ds)  # shape(1,229)\n",
    "        stim_outputs.append(y_pred_raw.cpu().numpy()[0])\n",
    "\n",
    "    stim_arr= np.stack(stim_outputs, axis=0)  # (stim_samples,229)\n",
    "    pca= PCA(n_components=subspace_dim)\n",
    "    pca.fit(stim_arr)\n",
    "    stim_subspace= pca.components_.T  # (229, subspace_dim)\n",
    "    return stim_subspace\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# 3) Overlap / Shared Dimension + Subspace Variance\n",
    "###############################################################################\n",
    "def orthonormalize_subspace(subspace):\n",
    "    \"\"\"\n",
    "    subspace: shape(229, d).\n",
    "    We'll do a QR or SVD to ensure columns are orthonormal. Returns shape(229, d).\n",
    "    \"\"\"\n",
    "    # shape(229, d)\n",
    "    Q,_= np.linalg.qr(subspace)\n",
    "    return Q\n",
    "\n",
    "def project_out_subspace(X, Y):\n",
    "    \"\"\"\n",
    "    Removes from X all components that lie in Y, assuming Y is orthonormal. \n",
    "    X shape(229, dX), Y shape(229, dY).\n",
    "    Returns X - Y(Y^T X).\n",
    "    \"\"\"\n",
    "    proj= Y@(Y.T@ X)\n",
    "    return X- proj\n",
    "\n",
    "def measure_variance_in_data(data, basis):\n",
    "    \"\"\"\n",
    "    data shape(229,T), basis shape(229,d).\n",
    "    We'll project => basis^T data => shape(d,T), sum squares / T => variance\n",
    "    \"\"\"\n",
    "    coords= basis.T@ data\n",
    "    var_ = np.sum(coords**2)/ data.shape[1]\n",
    "    return var_\n",
    "\n",
    "def find_shared_dimension(face_subspace, stim_subspace):\n",
    "    \"\"\"\n",
    "    face_subspace => shape(229, df), stim_subspace => shape(229, ds). \n",
    "    We'll do M= (face_subspace^T) (stim_subspace) => shape(df, ds).\n",
    "    SVD => top singular vector => direction in face_subspace that best overlaps stim_subspace.\n",
    "    Then in 229D => face_subspace @ U[:,0], etc.\n",
    "    We'll keep top 1 dimension for demonstration. \n",
    "    \"\"\"\n",
    "    # ensure both subspaces are orthonormal\n",
    "    F_ortho= orthonormalize_subspace(face_subspace)\n",
    "    S_ortho= orthonormalize_subspace(stim_subspace)\n",
    "    M= F_ortho.T@ S_ortho  # shape(df, ds)\n",
    "    U,s, Vt= np.linalg.svd(M, full_matrices=False)\n",
    "    # top left singular vector => U[:,0] in face subspace\n",
    "    u_face= U[:,0]  # shape(df,)\n",
    "    # in 229D => F_ortho@ u_face\n",
    "    shared_dim= F_ortho@ u_face  # shape(229,)\n",
    "    # normalize\n",
    "    nrm= np.linalg.norm(shared_dim)\n",
    "    if nrm> 1e-12:\n",
    "        shared_dim/= nrm\n",
    "    return shared_dim.reshape(-1,1)  # shape(229,1)\n",
    "\n",
    "def analyze_subspaces(model, ds, device='cuda',\n",
    "                      face_dim=10, stim_dim=10,\n",
    "                      face_samples=500, stim_samples=500,\n",
    "                      test_samples=None,\n",
    "                      do_null_test=True,\n",
    "                      random_seed=42):\n",
    "    \"\"\"\n",
    "    1) build face_subspace, stim_subspace\n",
    "    2) find shared dimension\n",
    "    3) define face-only, stim-only => project out shared\n",
    "    4) measure variance in test_data\n",
    "    5) if do_null_test => build random subspace to see typical overlap\n",
    "    \"\"\"\n",
    "    if random_seed is not None:\n",
    "        np.random.seed(random_seed)\n",
    "        torch.manual_seed(random_seed)\n",
    "\n",
    "    face_sub= build_face_subspace(model, ds, face_samples, face_dim, device=device)\n",
    "    stim_sub= build_stim_subspace(model, ds, stim_samples, stim_dim, device=device)\n",
    "    shared_dim= find_shared_dimension(face_sub, stim_sub)  # shape(229,1)\n",
    "\n",
    "    # face-only => face_sub - shared\n",
    "    face_sub_ortho= orthonormalize_subspace(face_sub)\n",
    "    face_only= project_out_subspace(face_sub_ortho, shared_dim)\n",
    "    face_only= orthonormalize_subspace(face_only)\n",
    "\n",
    "    # stim-only => stim_sub - shared\n",
    "    stim_sub_ortho= orthonormalize_subspace(stim_sub)\n",
    "    stim_only= project_out_subspace(stim_sub_ortho, shared_dim)\n",
    "    stim_only= orthonormalize_subspace(stim_only)\n",
    "\n",
    "    print(f\"face_sub: {face_sub.shape}, stim_sub: {stim_sub.shape}, shared_dim => shape(229,1)\")\n",
    "\n",
    "    # 4) measure variance in test_data => shape(229,T)\n",
    "    if test_samples is None:\n",
    "        # gather entire ds, predict MLP => raw domain\n",
    "        # build => shape(229, T)\n",
    "        loader= DataLoader(ds, batch_size=128, shuffle=False)\n",
    "        all_preds=[]\n",
    "        means= ds.means.to(device)\n",
    "        stds= ds.stds.to(device)\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for x_batch,yb in loader:\n",
    "                x_batch= x_batch.to(device)\n",
    "                preds_norm= model(x_batch)\n",
    "                preds_raw= preds_norm* stds + means\n",
    "                all_preds.append(preds_raw.cpu().numpy())\n",
    "        test_data_np= np.concatenate(all_preds, axis=0).T  # shape(229, T)\n",
    "    else:\n",
    "        # user can pass their own test_data => shape(229,T)\n",
    "        test_data_np= test_samples\n",
    "\n",
    "    total_var= np.sum(test_data_np**2)/ test_data_np.shape[1]\n",
    "    var_shared= measure_variance_in_data(test_data_np, shared_dim)\n",
    "    var_faceonly= measure_variance_in_data(test_data_np, face_only)\n",
    "    var_stimonly= measure_variance_in_data(test_data_np, stim_only)\n",
    "\n",
    "    sum_ = var_shared+ var_faceonly+ var_stimonly\n",
    "\n",
    "    print(f\"Total variance= {total_var:.4f}\")\n",
    "    print(f\"Shared variance= {var_shared:.4f} => {100*var_shared/total_var:.2f}%\")\n",
    "    print(f\"Face-only variance= {var_faceonly:.4f} => {100*var_faceonly/total_var:.2f}%\")\n",
    "    print(f\"Stim-only variance= {var_stimonly:.4f} => {100*var_stimonly/total_var:.2f}%\")\n",
    "    print(f\"Sum of subspace var= {sum_:.4f} => leftover= {total_var- sum_:.4f}\")\n",
    "\n",
    "    # 5) optional: do null test => random subspaces\n",
    "    if do_null_test:\n",
    "        # e.g. build random subspace shape(229, face_dim), random subspace shape(229, stim_dim), measure overlap\n",
    "        # see typical angle or overlap\n",
    "        # or do random labeling approach\n",
    "\n",
    "        # We'll just do random subspace approach\n",
    "        def random_subspace(dim):\n",
    "            mat= np.random.randn(229,dim)\n",
    "            Q,_= np.linalg.qr(mat)\n",
    "            return Q\n",
    "\n",
    "        rand_face= random_subspace(face_dim)\n",
    "        rand_stim= random_subspace(stim_dim)\n",
    "        # measure overlap => we can do a simple measure => \\|rand_face^T rand_stim\\|_F^2\n",
    "        overlap_null= np.linalg.norm(rand_face.T@ rand_stim, 'fro')**2\n",
    "        print(f\"Null test: random subspace overlap= {overlap_null:.4f} (dims= {face_dim}, {stim_dim})\")\n",
    "\n",
    "        # we can do repeated times to get a distribution if we want\n",
    "        # ...\n",
    "\n",
    "    # done\n",
    "    return {\n",
    "        'face_sub': face_sub,\n",
    "        'stim_sub': stim_sub,\n",
    "        'shared_dim': shared_dim,\n",
    "        'face_only': face_only,\n",
    "        'stim_only': stim_only,\n",
    "        'var_shared': var_shared,\n",
    "        'var_faceonly': var_faceonly,\n",
    "        'var_stimonly': var_stimonly,\n",
    "        'total_var': total_var\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd972ede-0828-4408-9b82-085ab628955e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "analyze_subspaces(model, ds_full, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8d41bb-3f09-460f-97f0-c6be4e633362",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "import scipy.io\n",
    "\n",
    "def invert_normalization(pred_norm, ds):\n",
    "    \"\"\"\n",
    "    Convert predicted normalized (N,229) back to raw domain using ds.means, ds.stds.\n",
    "    \"\"\"\n",
    "    device = pred_norm.device\n",
    "    means = ds.means.to(device)   # shape(229,)\n",
    "    stds  = ds.stds.to(device)\n",
    "    return pred_norm * stds + means\n",
    "\n",
    "def analyze_face_stim_orthogonality(model, ds_full, \n",
    "                                    M=100, K=10,\n",
    "                                    sub_pcs=3,\n",
    "                                    device='cuda',\n",
    "                                    random_seed=None,\n",
    "                                    null_hypothesis_mode=False):\n",
    "    \"\"\"\n",
    "    1) Baseline => x_base=0 => model => y_base\n",
    "    2) Face-driven => keep face from real sample, set stim=0 (last 4 dims)\n",
    "    3) Stim-driven => keep stim from real sample, set face to the mean of the first 500 dims\n",
    "    4) Possibly do a 'null hypothesis' mode: e.g. face vs. face\n",
    "    5) Measure subspace overlap\n",
    "    6) 2D PCA plot\n",
    "    7) Save the predicted face and stim outputs to .npy and .mat files.\n",
    "    \"\"\"\n",
    "\n",
    "    model.eval()\n",
    "    if random_seed is not None:\n",
    "        np.random.seed(random_seed)\n",
    "        torch.manual_seed(random_seed)\n",
    "\n",
    "    # Baseline\n",
    "    x_base = torch.zeros(1, 504, dtype=torch.float32).to(device)\n",
    "    with torch.no_grad():\n",
    "        y_base_norm = model(x_base)[0]  # shape(229,)\n",
    "\n",
    "    N = len(ds_full)\n",
    "    \n",
    "    if not null_hypothesis_mode:\n",
    "        # normal scenario => face vs. stim\n",
    "        idxs = np.random.choice(N, M + K, replace=False)\n",
    "        face_idxs = idxs[:M]\n",
    "        stim_idxs = idxs[M:]\n",
    "\n",
    "        # face-driven\n",
    "        x_face_list = []\n",
    "        for i in face_idxs:\n",
    "            x_raw, _ = ds_full[i]\n",
    "            x_mod = x_raw.clone()\n",
    "            # zero out stim => last 4\n",
    "            x_mod[500:] = 0.0\n",
    "            x_face_list.append(x_mod)\n",
    "        x_face_all = torch.stack(x_face_list, dim=0).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            y_face_norm = model(x_face_all)\n",
    "        y_face_norm = y_face_norm - y_base_norm\n",
    "\n",
    "        # stim-driven\n",
    "        x_stim_list = []\n",
    "        for j in stim_idxs:\n",
    "            x_raw, _ = ds_full[j]\n",
    "            x_mod = x_raw.clone()\n",
    "            # Replace the first 500 dims (face) with their mean\n",
    "            mean_face = x_mod[:500].mean()\n",
    "            x_mod[:500] = mean_face\n",
    "            x_stim_list.append(x_mod)\n",
    "        x_stim_all = torch.stack(x_stim_list, dim=0).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            y_stim_norm = model(x_stim_all)\n",
    "        y_stim_norm = y_stim_norm - y_base_norm\n",
    "\n",
    "        # invert to raw\n",
    "        y_face_raw = invert_normalization(y_face_norm, ds_full)\n",
    "        y_stim_raw = invert_normalization(y_stim_norm, ds_full)\n",
    "\n",
    "        face_np = y_face_raw.cpu().numpy()\n",
    "        stim_np = y_stim_raw.cpu().numpy()\n",
    "\n",
    "        label_face = 'Face-driven'\n",
    "        label_stim = 'Stim-driven'\n",
    "\n",
    "        # --- Save to npy and mat files ---\n",
    "        np.save('face_predictions.npy', face_np)\n",
    "        np.save('stim_predictions.npy', stim_np)\n",
    "\n",
    "        scipy.io.savemat('face_predictions.mat', {'face_predictions': face_np})\n",
    "        scipy.io.savemat('stim_predictions.mat', {'stim_predictions': stim_np})\n",
    "\n",
    "    else:\n",
    "        # Null hypothesis => let's do face vs. face\n",
    "        idxs = np.random.choice(N, M + K, replace=False)\n",
    "        setA_idxs = idxs[:M]\n",
    "        setB_idxs = idxs[M:]\n",
    "\n",
    "        xA_list = []\n",
    "        for i in setA_idxs:\n",
    "            x_raw, _ = ds_full[i]\n",
    "            x_mod = x_raw.clone()\n",
    "            x_mod[500:] = 0.0\n",
    "            xA_list.append(x_mod)\n",
    "        xA_all = torch.stack(xA_list, dim=0).to(device)\n",
    "        with torch.no_grad():\n",
    "            yA_norm = model(xA_all)\n",
    "        yA_norm = yA_norm - y_base_norm\n",
    "        yA_raw = invert_normalization(yA_norm, ds_full)\n",
    "        setA_np = yA_raw.cpu().numpy()\n",
    "\n",
    "        xB_list = []\n",
    "        for j in setB_idxs:\n",
    "            x_raw, _ = ds_full[j]\n",
    "            x_mod = x_raw.clone()\n",
    "            x_mod[500:] = 0.0\n",
    "            xB_list.append(x_mod)\n",
    "        xB_all = torch.stack(xB_list, dim=0).to(device)\n",
    "        with torch.no_grad():\n",
    "            yB_norm = model(xB_all)\n",
    "        yB_norm = yB_norm - y_base_norm\n",
    "        yB_raw = invert_normalization(yB_norm, ds_full)\n",
    "        setB_np = yB_raw.cpu().numpy()\n",
    "\n",
    "        face_np = setA_np\n",
    "        stim_np = setB_np\n",
    "        label_face = 'Set A (face/fake)'\n",
    "        label_stim = 'Set B (face/fake)'\n",
    "\n",
    "        # (optional) If you want to save the null-hypothesis sets as well:\n",
    "        np.save('setA_null_predictions.npy', face_np)\n",
    "        np.save('setB_null_predictions.npy', stim_np)\n",
    "        scipy.io.savemat('setA_null_predictions.mat', {'setA_null_predictions': face_np})\n",
    "        scipy.io.savemat('setB_null_predictions.mat', {'setB_null_predictions': stim_np})\n",
    "\n",
    "    # measure subspace overlap\n",
    "    pca_face = PCA(n_components=sub_pcs).fit(face_np)\n",
    "    U_face = pca_face.components_.T\n",
    "    pca_stim = PCA(n_components=sub_pcs).fit(stim_np)\n",
    "    U_stim = pca_stim.components_.T\n",
    "\n",
    "    overlap = np.linalg.norm(U_face.T @ U_stim, 'fro') ** 2\n",
    "    print(f\"Subspace overlap (top {sub_pcs} PCs) = {overlap:.4f}\")\n",
    "\n",
    "    # angle top1\n",
    "    face_pc1 = U_face[:, 0]\n",
    "    stim_pc1 = U_stim[:, 0]\n",
    "    dot = np.dot(face_pc1, stim_pc1)\n",
    "    denom = np.linalg.norm(face_pc1) * np.linalg.norm(stim_pc1) + 1e-12\n",
    "    angle_deg = np.degrees(np.arccos(dot / denom))\n",
    "    print(f\"Angle between top1 PC: {angle_deg:.2f} deg\")\n",
    "\n",
    "    # 2D PCA\n",
    "    all_data = np.concatenate([face_np, stim_np], axis=0)\n",
    "    pca_2d = PCA(n_components=2)\n",
    "    all_2d = pca_2d.fit_transform(all_data)\n",
    "    M_ = face_np.shape[0]\n",
    "\n",
    "    plt.figure(figsize=(6,5))\n",
    "    plt.scatter(all_2d[:M_, 0], all_2d[:M_, 1], alpha=0.6, label=label_face)\n",
    "    plt.scatter(all_2d[M_:, 0], all_2d[M_:, 1], alpha=0.6, label=label_stim)\n",
    "    plt.title(\"Face vs. Stimz Subspace\" if not null_hypothesis_mode else \"Null Hypothesis (Face vs. Face)\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6fef6c-f329-4fe3-ba7a-60013e7e353f",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_face_stim_orthogonality(model, ds_full, \n",
    "                                    M=1000, K=500,\n",
    "                                    sub_pcs=3,\n",
    "                                    device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6555dbfe-8ff1-42cb-9b17-7c3d5b5d623c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def invert_normalization(pred_norm, ds):\n",
    "    \"\"\"\n",
    "    Convert predicted normalized (N,229) back to raw domain \n",
    "    using ds.means, ds.stds from the training dataset.\n",
    "    \"\"\"\n",
    "    device = pred_norm.device\n",
    "    means = ds.means.to(device)   # shape(229,)\n",
    "    stds  = ds.stds.to(device)\n",
    "    return pred_norm * stds + means\n",
    "\n",
    "\n",
    "def compute_average_face(ds_full):\n",
    "    \"\"\"\n",
    "    Compute the average face vector (dim=500) across ALL samples in ds_full.\n",
    "    ds_full[i] returns (x_in, y_in) with x_in of size (504,). The first 500 \n",
    "    are face, the last 4 are stimulus.\n",
    "    \"\"\"\n",
    "    all_faces = []\n",
    "    for i in range(len(ds_full)):\n",
    "        x_in, _ = ds_full[i]       # x_in: shape(504,)\n",
    "        face_part = x_in[:500]     # shape(500,)\n",
    "        all_faces.append(face_part)\n",
    "    all_faces = torch.stack(all_faces, dim=0)  # (N, 500)\n",
    "    avg_face = all_faces.mean(dim=0)           # (500,)\n",
    "    return avg_face\n",
    "\n",
    "\n",
    "def predict_stim_no_face_motion(model, ds_full, device='cuda'):\n",
    "    \"\"\"\n",
    "    1) Compute f(stimulus, no-face-motion).\n",
    "       - no-face-motion = average of face dims across entire dataset\n",
    "       - stimulus = one-hot for each of the 4 conditions\n",
    "    2) Return predictions in shape (229, 4).\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    avg_face = compute_average_face(ds_full).to(device)  # (500,)\n",
    "\n",
    "    # We have 4 stimulus conditions => one-hot vectors\n",
    "    # [1,0,0,0], [0,1,0,0], [0,0,1,0], [0,0,0,1]\n",
    "    stim_inputs = []\n",
    "    for c in range(4):\n",
    "        x_in = torch.zeros(504, dtype=torch.float32, device=device)\n",
    "        x_in[:500] = avg_face\n",
    "        x_in[500 + c] = 1.0  # one-hot\n",
    "        stim_inputs.append(x_in)\n",
    "    stim_inputs = torch.stack(stim_inputs, dim=0)  # (4, 504)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pred_norm = model(stim_inputs)  # (4, 229)\n",
    "        pred_raw = invert_normalization(pred_norm, ds_full)  # (4, 229)\n",
    "\n",
    "    # Transpose to shape (229,4) so each column is a different stim condition\n",
    "    pred_raw = pred_raw.cpu().numpy().T\n",
    "    return pred_raw\n",
    "\n",
    "\n",
    "def predict_no_stim_face_motion(model, eigenface_evoked, ds_full, device='cuda'):\n",
    "    \"\"\"\n",
    "    1) Compute f(no-stimulus, face-motion).\n",
    "       - no-stimulus = [0,0,0,0] in the last 4 dims\n",
    "       - face-motion = all columns from the 4 evoked conditions (4 * 1000 = 4000)\n",
    "    2) Return predictions in shape (229, 4000).\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    # We assume eigenface_evoked has shape (500, 1000, 4)\n",
    "    # i.e. 500 face dims, 1000 time columns, 4 stim conditions\n",
    "    # We'll gather all face columns => total 4000\n",
    "\n",
    "    face_motion_list = []\n",
    "    for c in range(4):\n",
    "        face_block = eigenface_evoked[:, :, c]  # shape (500, 1000)\n",
    "        # For each of the 1000 columns in this condition:\n",
    "        for col in range(1000):\n",
    "            face_col = face_block[:, col]  # shape (500,)\n",
    "            x_in = torch.zeros(504, dtype=torch.float32)\n",
    "            x_in[:500] = torch.from_numpy(face_col)\n",
    "            # no stimulus => last 4 dims = 0\n",
    "            face_motion_list.append(x_in)\n",
    "\n",
    "    face_motion_tensor = torch.stack(face_motion_list, dim=0).to(device)  # (4000, 504)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pred_norm = model(face_motion_tensor)         # (4000, 229)\n",
    "        pred_raw = invert_normalization(pred_norm, ds_full)  # (4000, 229)\n",
    "\n",
    "    # shape => (4000, 229), transpose => (229, 4000)\n",
    "    pred_raw = pred_raw.cpu().numpy().T\n",
    "    return pred_raw\n",
    "\n",
    "\n",
    "def main(model, ds_full, eigenface_evoked, device='cuda'):\n",
    "    \"\"\"\n",
    "    Drives the two predictions and saves them to disk.\n",
    "    \"\"\"\n",
    "    # 1) f(stimulus, no-face-motion)\n",
    "    stim_no_face = predict_stim_no_face_motion(model, ds_full, device=device)\n",
    "    print(\"stim_no_face shape:\", stim_no_face.shape)  # should be (229, 4)\n",
    "    np.save(\"pred_stim_no_face_motion.npy\", stim_no_face)\n",
    "\n",
    "    # 2) f(no-stimulus, face-motion)\n",
    "    no_stim_face = predict_no_stim_face_motion(model, eigenface_evoked, ds_full, device=device)\n",
    "    print(\"no_stim_face shape:\", no_stim_face.shape)  # should be (229, 4000)\n",
    "    np.save(\"pred_no_stim_face_motion.npy\", no_stim_face)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage:  (assuming you already have model, ds_full, eigenface_evoked from prior steps)\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    # model, ds_full = ...  # from your training code\n",
    "    # eigenface_evoked = ...  # loaded from the .mat file\n",
    "\n",
    "    # Call our main routine\n",
    "    main(model, ds_full, eigenface_evoked, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27284d7b-60ad-49c0-bc04-a69eb695a23a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
